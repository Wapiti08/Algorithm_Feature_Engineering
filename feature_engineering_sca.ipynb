{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the notebook to explore different normalization method to the final learning result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "I use the data from [Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) to explore the potential problems I have mentioned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "# diaplay all the columns\n",
    "pd.pandas.set_option(\"display.max_columns\", None)\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "data.drop(\"Id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prediction target\n",
    "data['SalePrice']\n",
    "\n",
    "# get the categorical and numerical featuers\n",
    "car_feas = [fea for fea in data.columns if data[fea].dtype == 'O']\n",
    "## add MSSubClass to cate features\n",
    "car_feas = car_feas + ['MSSubClass']\n",
    "## cast all variables as categorical\n",
    "data[car_feas] = data[car_feas].astype('O')\n",
    "\n",
    "num_feas = [fea for fea in data.columns if fea not in car_feas and fea not in [\"SalePrice\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, Normalizer\n",
    "import joblib\n",
    "\n",
    "\n",
    "X_train,X_test,y_train, y_test = train_test_split(\n",
    "    data.drop([ 'SalePrice'],axis=1),\n",
    "    data['SalePrice'],\n",
    "    test_size=0.1,\n",
    "    random_state=0 \n",
    ")\n",
    "\n",
    "# handle skewed distribution in prediction matrix\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processing categorical variables\n",
    "\n",
    "replace missing value with the string 'missing' or the most frequent category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find features with missing values\n",
    "car_feas_with_na = [\n",
    "    fea for fea in car_feas\n",
    "    if X_train[fea].isnull().sum()>0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the features with high ratio with missing values -- replace with missing\n",
    "fea_str_missing = [\n",
    "    fea for fea in car_feas_with_na if X_train[fea].isnull().mean() > 0.1\n",
    "]\n",
    "\n",
    "# find the features with low ratio with missing values --- replace with most frequent category\n",
    "fea_str_category = [\n",
    "    fea for fea in car_feas_with_na if X_train[fea].isnull().mean() < 0.1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with string \"Missing\"\n",
    "X_train[fea_str_missing] = X_train[fea_str_missing].fillna(\"Missing\")\n",
    "X_test[fea_str_missing] = X_test[fea_str_missing].fillna(\"Missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fea in fea_str_category:\n",
    "    # The mode of a set of values is the value that appears most often\n",
    "    mode = X_train[fea].mode()[0]\n",
    "    X_train[fea].fillna(mode, inplace=True)\n",
    "    X_test[fea].fillna(mode, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processing numeric variable\n",
    "\n",
    "replace missing values with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fea in num_feas:\n",
    "    mean_val = data[fea].mean()\n",
    "    # add binary missing indicator\n",
    "    X_train[fea+'_na'] = np.where(X_train[fea].isnull(), 1, 0)\n",
    "    X_test[fea+'_na'] = np.where(X_test[fea].isnull(), 1, 0)\n",
    "\n",
    "    # replace missing values by the mean\n",
    "    X_train[fea].fillna(mean_val, inplace=True)\n",
    "    X_test[fea].fillna(mean_val, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numerical variable transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ren\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\stats\\morestats.py:1478: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(trans.var(axis=0))\n",
      "C:\\Users\\ren\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\optimize\\optimize.py:2371: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  w = xb - ((xb - xc) * tmp2 - (xb - xa) * tmp1) / denom\n",
      "C:\\Users\\ren\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\optimize\\optimize.py:1984: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp1 = (x - w) * (fx - fv)\n",
      "C:\\Users\\ren\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\optimize\\optimize.py:1985: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp2 = (x - v) * (fx - fw)\n"
     ]
    }
   ],
   "source": [
    "# logarithmic transformation ---- work only on positive numerical\n",
    "for var in [\"LotFrontage\", \"1stFlrSF\", \"GrLivArea\"]:\n",
    "    X_train[var] = np.log(X_train[var])\n",
    "    X_test[var] = np.log(X_test[var])\n",
    "\n",
    "# Yeo-Johnson transformation\n",
    "X_train['LotArea'], param = stats.yeojohnson(X_train['LotArea'])\n",
    "X_test['LotArea'] = stats.yeojohnson(X_test['LotArea'], lmbda=param)\n",
    "\n",
    "# for very skewed variables, using Binary transformation\n",
    "skewed = [\n",
    "    'BsmtFinSF2', 'LowQualFinSF', 'EnclosedPorch',\n",
    "    '3SsnPorch', 'ScreenPorch', 'MiscVal'\n",
    "]\n",
    "\n",
    "for var in skewed:\n",
    "    # map the variable values into 0 and 1\n",
    "    X_train[var] = np.where(X_train[var]==0, 0, 1)\n",
    "    X_test[var] = np.where(X_test[var]==0, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features Mappings\n",
    "\n",
    "the values in some features have an assigned order, the mapping is used here to convert them into numeric data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_mappings = {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5, 'Missing': 0, np.NaN: 0}\n",
    "\n",
    "qual_feas = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond',\n",
    "             'HeatingQC', 'KitchenQual', 'FireplaceQu',\n",
    "             'GarageQual', 'GarageCond',\n",
    "            ]\n",
    "\n",
    "for fea in qual_feas:\n",
    "    X_train[fea] = X_train[fea].map(qual_mappings)\n",
    "    X_test[fea] = X_test[fea].map(qual_mappings)\n",
    "\n",
    "exposure_mappings = {'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4, np.NaN: 0}\n",
    "\n",
    "X_train['BsmtExposure'] = X_train['BsmtExposure'].map(exposure_mappings)\n",
    "X_test['BsmtExposure'] = X_test['BsmtExposure'].map(exposure_mappings)\n",
    "\n",
    "finish_mappings = {'Missing': 0, np.NaN: 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6}\n",
    "\n",
    "finish_vars = ['BsmtFinType1', 'BsmtFinType2']\n",
    "\n",
    "for var in finish_vars:\n",
    "    X_train[var] = X_train[var].map(finish_mappings)\n",
    "    X_test[var] = X_test[var].map(finish_mappings)\n",
    "\n",
    "garage_mappings = {'Missing': 0, np.NaN: 0, 'Unf': 1, 'RFn': 2, 'Fin': 3}\n",
    "\n",
    "X_train['GarageFinish'] = X_train['GarageFinish'].map(garage_mappings)\n",
    "X_test['GarageFinish'] = X_test['GarageFinish'].map(garage_mappings)\n",
    "\n",
    "fence_mappings = {'Missing': 0, np.NaN: 0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv': 4}\n",
    "\n",
    "X_train['Fence'] = X_train['Fence'].map(fence_mappings)\n",
    "X_test['Fence'] = X_test['Fence'].map(fence_mappings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding of categorical variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_vars  = qual_feas + finish_vars + ['BsmtExposure','GarageFinish','Fence']\n",
    "\n",
    "# capture the remaining categorical variables\n",
    "# (those that we did not re-map)\n",
    "\n",
    "cat_others = [\n",
    "    var for var in car_feas if var not in qual_feas\n",
    "]\n",
    "\n",
    "def replace_categories(train, test, y_train, var, target):\n",
    "    \n",
    "    tmp = pd.concat([X_train, y_train], axis=1)\n",
    "    \n",
    "    # order the categories in a variable from that with the lowest\n",
    "    # house sale price, to that with the highest\n",
    "    ordered_labels = tmp.groupby([var])[target].mean().sort_values().index\n",
    "\n",
    "    # create a dictionary of ordered categories to integer values\n",
    "    ordinal_label = {k: i for i, k in enumerate(ordered_labels, 0)}\n",
    "    \n",
    "    # use the dictionary to replace the categorical strings by integers\n",
    "    train[var] = train[var].map(ordinal_label)\n",
    "    test[var] = test[var].map(ordinal_label)\n",
    "\n",
    "for var in cat_others:\n",
    "    replace_categories(X_train, X_test, y_train, var, 'SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_num_feas = [var for var in X_train.columns if X_train[var].isnull().sum() == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "*converting in the range [0,1] works particularly \n",
    "well if you are dealing with a sparse matrix and most of your values are zero* ---- Large Scale Machine Learning with Python\n",
    "\n",
    "I will compare four different methods here to explain the difference of them.\n",
    "\n",
    "[Normalizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer)     ---- normalize samples individually to unit norm, without inverse_transform\n",
    "\n",
    "[MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler)   ---- transform features by scaling each feature to a given range, with inverse_transform\n",
    "\n",
    "[RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler)   ---- Scale features using statistics that are robust to outliers, with inverse_transform\n",
    "\n",
    "[StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) ---- Standardize features by removing the mean and scaling to unit variance, with inverse_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[right_num_feas]\n",
    "X_test = X_test[right_num_feas]\n",
    "\n",
    "\n",
    "# test MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler = StandardScaler()\n",
    "# scaler = RobustScaler()\n",
    "scaler = Normalizer()\n",
    "#  fit  the scaler to the train set\n",
    "scaler.fit(X_train) \n",
    "\n",
    "# transform the train and test set\n",
    "\n",
    "# sklearn returns numpy arrays, so we wrap the\n",
    "# array with a pandas dataframe\n",
    "\n",
    "X_train = pd.DataFrame(\n",
    "    scaler.transform(X_train),\n",
    "    columns=X_train.columns\n",
    ")\n",
    "\n",
    "X_test = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    columns=X_train.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('xtrain.csv', index=False)\n",
    "X_test.to_csv('xtest.csv', index=False)\n",
    "\n",
    "y_train.to_csv('ytrain.csv', index=False)\n",
    "y_test.to_csv('ytest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import Lasso\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pd.read_csv('xtrain.csv')\n",
    "# X_test = pd.read_csv('xtest.csv')\n",
    "\n",
    "# y_train = pd.read_csv('ytrain.csv')\n",
    "# y_test = pd.read_csv('ytest.csv')\n",
    "\n",
    "# sel_ = SelectFromModel(Lasso(alpha=0.001, random_state=0))\n",
    "# sel_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to build the model\n",
    "import pandas as pd\n",
    "# to evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "X_train = pd.read_csv('xtrain.csv')\n",
    "X_test = pd.read_csv('xtest.csv')\n",
    "\n",
    "y_train = pd.read_csv('ytrain.csv')\n",
    "y_test = pd.read_csv('ytest.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.001, random_state=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_model = Lasso(alpha=0.001, random_state=0)\n",
    "\n",
    "# train the model\n",
    "\n",
    "lin_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse: 1448379939\n",
      "train rmse: 38057\n",
      "train r2: 0.768030278886929\n",
      "\n",
      "test mse: 2890698512\n",
      "test rmse: 53765\n",
      "test r2: 0.5793582628440888\n",
      "\n",
      "Average house price:  163000\n"
     ]
    }
   ],
   "source": [
    "# make predictions for train set\n",
    "pred = lin_model.predict(X_train)\n",
    "\n",
    "# determine mse, rmse and r2\n",
    "print('train mse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_train), np.exp(pred)))))\n",
    "print('train rmse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_train), np.exp(pred), squared=False))))\n",
    "print('train r2: {}'.format(\n",
    "    r2_score(np.exp(y_train), np.exp(pred))))\n",
    "print()\n",
    "\n",
    "# make predictions for test set\n",
    "pred = lin_model.predict(X_test)\n",
    "\n",
    "# determine mse, rmse and r2\n",
    "print('test mse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_test), np.exp(pred)))))\n",
    "print('test rmse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_test), np.exp(pred), squared=False))))\n",
    "print('test r2: {}'.format(\n",
    "    r2_score(np.exp(y_test), np.exp(pred))))\n",
    "print()\n",
    "\n",
    "print('Average house price: ', int(np.exp(y_train).median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinMaxScaler:\n",
    "    \n",
    "    - train mse: 844795172\n",
    "    - train rmse: 29065\n",
    "    - train r2: 0.8646992440387936\n",
    "\n",
    "    - test mse: 1116674539\n",
    "    - test rmse: 33416\n",
    "    - test r2: 0.8375064309369368\n",
    "\n",
    "    - Average house price:  163000\n",
    "\n",
    "StandardScaler:\n",
    "\n",
    "    - train mse: 692046354\n",
    "    - train rmse: 26306\n",
    "    - train r2: 0.8891631985314724\n",
    "\n",
    "    - test mse: 1257957480\n",
    "    - test rmse: 35467\n",
    "    - test r2: 0.8169475586394037\n",
    "\n",
    "    - Average house price:  16300\n",
    "\n",
    "RobustScaler:\n",
    "\n",
    "    - train mse: 697763515\n",
    "    - train rmse: 26415\n",
    "    - train r2: 0.8882475491126485\n",
    "\n",
    "    - test mse: 1290265505\n",
    "    - test rmse: 35920\n",
    "    - test r2: 0.8122462368902384\n",
    "\n",
    "    - Average house price:  163000\n",
    "\n",
    "Normalizer:\n",
    "\n",
    "    - train mse: 1448379939\n",
    "    - train rmse: 38057\n",
    "    - train r2: 0.768030278886929\n",
    "\n",
    "    - test mse: 2890698512\n",
    "    - test rmse: 53765\n",
    "    - test r2: 0.5793582628440888\n",
    "\n",
    "    - Average house price:  163000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fecd871876602184e2def9d040398806a20c493ba8c7291bbd5a5358628e6cd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
